{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneOut, cross_val_predict\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Adjust these to address the current train data and the path where the model needs to be saved + the name\n",
    "DATA_PATH = \"../data/train_data/INSRTR_SAR.csv\"\n",
    "MODEL_PATH = \"../insrtr/models/gbt_classifier_v2.pkl\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def encode_categories(dataframe_to_encode):\n",
    "    \"\"\"\n",
    "    Encodes categories using cat.codes from scikit.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe_to_encode: input dataframe\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dataframe_to_encode: modified dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    cols_to_encode = [\"Enzyme\", \"resi_type\", \"resi_dssp\", \"prev_resi_type\", \"prev_resi_dssp\", \"next_resi_type\",\n",
    "                      \"next_resi_dssp\", \"loop_seq\"]\n",
    "    encoded_cols = [col + \"_encoded\" for col in cols_to_encode]\n",
    "    # Apply astype and cat.codes to each column\n",
    "    encoded = dataframe_to_encode[cols_to_encode].apply(lambda column: column.astype(\"category\").cat.codes)\n",
    "    # Use assign to create new columns in dataframe\n",
    "    dataframe_to_encode = dataframe_to_encode.assign(**dict(zip(encoded_cols, encoded.T.values)))\n",
    "    return dataframe_to_encode\n",
    "\n",
    "\n",
    "def create_x_y(dataframe_to_split, target=\"\"):\n",
    "    \"\"\"\n",
    "    Splits the data into descriptive space (x) and target space (y).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe_to_split: input dataframe\n",
    "    target: string that represents the target column\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x_array: descriptive space numpy array\n",
    "    y_array: target space numpy array\n",
    "\n",
    "    \"\"\"\n",
    "    x_array = dataframe_to_split.drop(\n",
    "        [\"max_fold_decrease_with_peptide\", \"%WT_activity\", \"works\", \"fluctuation\", \"relative_MSA_conservation\",\n",
    "         \"Enzyme_encoded\", \"Enzyme\", \"resi_type\", \"resi_dssp\", \"prev_resi_type\", \"prev_resi_dssp\",\n",
    "         \"next_resi_type\", \"next_resi_dssp\", \"loop_seq\"], axis=1).iloc[:, :].copy().values\n",
    "    y_array = dataframe_to_split[target].values.ravel()\n",
    "    return x_array, y_array\n",
    "\n",
    "\n",
    "def save_model(classifier, filename):\n",
    "    \"\"\"\n",
    "    Saves a scikit-learn model to disk using the pickle module.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    classifier: trained model that should be saved\n",
    "    filename: where the pickle file is saved\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    with open(filename, \"wb\") as file:\n",
    "        dump(classifier, file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leave-one-out cross-validation score on tuning set: 0.5789\n",
      "Test set score: 0.5556\n",
      "23-fold cross-validation score on entire dataset: 0.5942\n",
      "LOOCV score on entire dataset: 0.6596\n",
      "Confusion matrix: \n",
      " [[17  6]\n",
      " [10 14]]\n",
      "AUC score: 0.6902\n"
     ]
    }
   ],
   "source": [
    "# Initialize model and cross-validation setting\n",
    "clf = GradientBoostingClassifier(n_estimators=800, random_state=42, learning_rate=4)\n",
    "cv = LeaveOneOut()\n",
    "\n",
    "# Read data, drop embeddings and dummy columns, filer out rows with missing target\n",
    "df = pd.read_csv(DATA_PATH, usecols=lambda col: \"esm2\" not in col and \"Unnamed\" not in col).dropna(\n",
    "    subset=[\"works\"])\n",
    "df = encode_categories(df)\n",
    "\n",
    "# Parameter tuning scenario\n",
    "# First do a test where the entire set is split into two parts, 80-20 - train and test sets.\n",
    "# The train set will be used for leave-one-out cross-validation (LOOCv) to tune the model, the second for testing.\n",
    "# Then do k-fold cross-validation on entire dataset.\n",
    "# Results should not vary significantly.\n",
    "df_shuff = df.sample(frac=1, random_state=48).reset_index(drop=True)\n",
    "n_test = int(len(df_shuff) * 0.2)\n",
    "tune_set = df_shuff[n_test:]\n",
    "test_set = df_shuff[:n_test]\n",
    "x_tune, y_tune = create_x_y(tune_set, \"works\")\n",
    "# LOOCV on train set\n",
    "scores = cross_val_score(clf, x_tune, y_tune, scoring=\"accuracy\", cv=cv, n_jobs=-1)\n",
    "avg_score = scores.mean()\n",
    "print(\"Leave-one-out cross-validation score on tuning set: {:.4f}\".format(avg_score))\n",
    "# Try model on test set\n",
    "x_test, y_test = create_x_y(test_set, \"works\")\n",
    "clf.fit(x_tune, y_tune)\n",
    "clf.predict(x_test)\n",
    "test_score = clf.score(x_test, y_test)\n",
    "print(\"Test set score: {:.4f}\".format(test_score))\n",
    "# Try 23-fold cross validation on entire dataset\n",
    "x, y = create_x_y(df, \"works\")\n",
    "scores = cross_val_score(clf, x, y, scoring=\"accuracy\", cv=23, n_jobs=-1)\n",
    "avg_score = scores.mean()\n",
    "print(\"23-fold cross-validation score on entire dataset: {:.4f}\".format(avg_score))\n",
    "\n",
    "# LOOCV on entire dataset\n",
    "x, y = create_x_y(df, \"works\")\n",
    "scores = cross_val_score(clf, x, y, scoring=\"accuracy\", cv=cv, n_jobs=-1)\n",
    "avg_score = scores.mean()\n",
    "print(\"LOOCV score on entire dataset: {:.4f}\".format(avg_score))\n",
    "# Get predictions from LOOCV - label and probability, calculate AUC and show confusion matrix\n",
    "y_pred_label = cross_val_predict(clf, x, y, cv=cv, n_jobs=-1)\n",
    "conf_mat = confusion_matrix(y, y_pred_label, labels=[\"N\", \"Y\"])\n",
    "print(\"Confusion matrix: \\n\", conf_mat)\n",
    "y_pred_proba = cross_val_predict(clf, x, y, cv=cv, method=\"predict_proba\", n_jobs=-1)\n",
    "y_pred_proba = y_pred_proba[:, 1]\n",
    "auc_score = roc_auc_score(y, y_pred_proba)\n",
    "print(\"AUC score: {:.4f}\".format(auc_score))\n",
    "\n",
    "# Retrain model on entire set and save it as pickle file\n",
    "clf.fit(x, y)\n",
    "save_model(clf, MODEL_PATH)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
